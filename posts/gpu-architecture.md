---
title: GPU 架构浅析
date: 2024-02-01
tags: [gpu, hardware, architecture]
category: 硬件基础
description: 从硬件层面理解 GPU 的工作原理，包括流式多处理器、线程束和内存层次结构。
---

# GPU 架构浅析

理解 GPU 硬件架构对于编写高效 CUDA 程序至关重要。本文将从硬件角度解析 GPU 的工作原理。

## GPU vs CPU 设计理念

```
┌─────────────────────────────────────────────────────────────┐
│                        CPU                                  │
│  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐       │
│  │  Core 1 │  │  Core 2 │  │  Core 3 │  │  Core 4 │  ...  │
│  └─────────┘  └─────────┘  └─────────┘  └─────────┘       │
│       ↑            ↑            ↑            ↑              │
│       └────────────┴────────────┴────────────┘              │
│                       控制单元                              │
│                      (复杂逻辑)                             │
│                       大容量缓存                            │
└─────────────────────────────────────────────────────────────┘

          VS

┌─────────────────────────────────────────────────────────────┐
│                        GPU                                  │
│  ┌─────────────────────────────────────────────────────┐   │
│  │              流式多处理器 (SM)                       │   │
│  │  ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐  │   │
│  │  │Core │ │Core │ │Core │ │Core │ │Core │ │Core │  │   │ x 16+
│  │  └─────┘ └─────┘ └─────┘ └─────┘ └─────┘ └─────┘  │   │
│  │              共享内存 / L1 缓存                      │   │
│  └─────────────────────────────────────────────────────┘   │
│  ┌─────────────────────────────────────────────────────┐   │
│  │              流式多处理器 (SM)                       │   │ x 16+
│  │              ...                                     │   │
│  └─────────────────────────────────────────────────────┘   │
│                      全局内存                              │
└─────────────────────────────────────────────────────────────┘
```

### 关键差异

| 特性 | CPU | GPU |
|-----|-----|-----|
| 核心数量 | 数十个 | 数万个 |
| 控制逻辑 | 复杂（分支预测、乱序执行） | 简单（单指令多数据） |
| 缓存 | 大容量、低延迟 | 小容量、高带宽 |
| 线程切换 | 慢（上下文切换） | 零开销（硬件调度） |
| 适用场景 | 串行、低延迟 | 并行、高吞吐 |

## 流式多处理器 (SM)

流式多处理器是 GPU 的基本计算单元：

```
┌─────────────────────────────────────────┐
│          流式多处理器 (SM)               │
├─────────────────────────────────────────┤
│  ┌───────────────────────────────────┐  │
│  │           指令缓存                 │  │
│  └───────────────────────────────────┘  │
│  ┌───────────────────────────────────┐  │
│  │           调度器 (Warp Scheduler)  │  │
│  └───────────────────────────────────┘  │
│  ┌───────────────────────────────────┐  │
│  │       线程束执行单元 (32 cores)    │  │
│  │  ┌──┐ ┌──┐ ┌──┐ ... ┌──┐ ┌──┐    │  │
│  │  │32│ │32│ │32│     │32│ │32│    │  │
│  │  └──┘ └──┘ └──┘     └──┘ └──┘    │  │
│  └───────────────────────────────────┘  │
│  ┌───────────────────────────────────┐  │
│  │     共享内存 / L1 缓存 (48-128KB)  │  │
│  └───────────────────────────────────┘  │
│  ┌───────────────────────────────────┐  │
│  │        纹理/常量缓存               │  │
│  └───────────────────────────────────┘  │
└─────────────────────────────────────────┘
```

### SM 核心组件

1. **线程束调度器 (Warp Scheduler)**
   - 每个周期选择就绪的线程束发射指令
   - 管理线程束的发射和执行

2. **执行单元 (Execution Units)**
   - 32 个 CUDA 核心（算术运算）
   - 16 个特殊函数单元（SFU，超越函数）
   - 4 个加载/存储单元（内存访问）

3. **共享内存 / L1 缓存**
   - 可配置大小（通常 48-128KB）
   - 线程块内所有线程共享
   - 带宽是全局内存的 10-100 倍

## 线程束 (Warp)

线程束是 GPU 并行的基本单位：

```cuda
// 一个线程束包含 32 个线程
int tid = threadIdx.x + blockIdx.x * blockDim.x;
// tid = 0, 1, 2, ... 31 属于同一个线程束
// tid = 32, 33, ... 63 属于下一个线程束
```

### 线程束执行特性

```cuda
// 所有 32 个线程同时执行
float a = input[tid];      // ✅ 合并内存访问
float b = input[tid + 32]; // ✅ 另一个线程束

// 条件分支导致线程分歧
if (tid % 2 == 0) {
    // 偶数线程执行
    a *= 2;
} else {
    // 奇数线程执行 - 与偶数线程串行执行
    a += 1;
}
// 性能损失：原来 1 条指令变成多条
```

### 避免分支分歧

```cuda
// 方法 1：使用掩码（推荐）
float a = input[tid];
float mask = (tid % 2 == 0) ? 1.0f : 0.0f;
a = a * mask + a * (1.0f - mask);  // 无分支

// 方法 2：重新组织数据
// 让相同条件的线程在同一个线程束中
__global__ void optimized_kernel(float* data, int n) {
    int tid = threadIdx.x;
    int lane = tid % 32;  // 线程束内的 lane ID
    int warp = tid / 32;  // 线程束 ID

    // 线程束内前 16 个线程处理偶数索引
    // 后 16 个线程处理奇数索引
    float val = (lane < 16) ? data[warp * 32 + lane * 2]
                            : data[warp * 32 + (lane - 16) * 2 + 1];
}
```

## 内存层次结构

```
┌──────────────────────────────────────────────────────────────┐
│                        内存带宽金字塔                         │
├──────────────────────────────────────────────────────────────┤
│                                                              │
│   寄存器 (Register)        12-20 TB/s        ~0.5-1 MB/SM   │
│         ↑                                                    │
│   共享内存 (Shared)        10-15 TB/s        48-128 KB/SM   │
│         ↑                                                    │
│   L1/L2 缓存               3-5 TB/s          128KB-50MB     │
│         ↑                                                    │
│   全局内存 (Global)        1-2 TB/s          8-80 GB        │
│         ↑                                                    │
│   显存带宽                                     带宽         │
│                                                              │
└──────────────────────────────────────────────────────────────┘
```

### 各层内存特性

| 内存类型 | 位置 | 访问速度 | 生命周期 | 可见范围 |
|---------|------|---------|---------|---------|
| 寄存器 | SM 内 | 最快 | 线程 | 线程私有 |
| 共享内存 | SM 内 | 很快 | 线程块 | 线程块内 |
| L1 缓存 | SM/芯片 | 快 | 程序 | 所有线程 |
| L2 缓存 | 芯片 | 中 | 程序 | 所有线程 |
| 全局内存 | 显存 | 慢 | 程序 | 所有线程 |
| 常量内存 | 显存 | 中 | 程序 | 所有线程 |

## GPU 线程层次结构

```
┌─────────────────────────────────────────────────────┐
│                   网格 (Grid)                        │
│                                                     │
│  ┌─────────────────────────────────────────────┐   │
│  │              线程块 0 (Block 0)              │   │
│  │  ┌───┐ ┌───┐ ┌───┐ ... ┌───┐ ┌───┐        │   │
│  │  │T0 │ │T1 │ │T2 │      │T30│ │T31│ (32线程)│   │
│  │  └───┘ └───┘ └───┘      └───┘ └───┘        │   │
│  └─────────────────────────────────────────────┘   │
│  ┌─────────────────────────────────────────────┐   │
│  │              线程块 1 (Block 1)              │   │
│  │                    ...                       │   │
│  └─────────────────────────────────────────────┘   │
│                    ...                             │
│                                                     │
└─────────────────────────────────────────────────────┘
```

### 线程层次配置示例

```cuda
// 配置线程层次
dim3 blockSize(256);    // 每个线程块 256 个线程
dim3 gridSize((n + blockSize.x - 1) / blockSize.x);  // 足够多的线程块

// 核函数
__global__ void kernel(float* data, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        data[idx] = compute(data[idx]);
    }
}

// 启动
kernel<<<gridSize, blockSize>>>(d_data, n);
```

### 选择合适的线程块大小

```cuda
// 一般原则：每个 SM 保持 4-8 个活跃线程块

// 小型计算（占用资源少）：128-256 线程/块
// 大型共享内存使用：64-128 线程/块
// 归约操作：256-512 线程/块（更多线程增加并行度）
```

## SM 利用率与Occupancy

**Occupancy（占用率）** = 活跃线程束数 / 最大线程束数

```cuda
// 计算占用率的工具函数
__global__ void occupancy_demo() {
    // 计算当前线程块的资源使用
    // ...

    // 占用率 = (活跃线程束数) / (SM最大线程束数)
}
```

### 提升占用率的技巧

1. **增加线程块大小**
2. **减少共享内存使用**
3. **减少寄存器使用**（使用 `-maxrregcount` 编译选项）
4. **避免过多的本地数组**

## 总结

理解 GPU 架构的关键点：

1. **线程束执行**：32 个线程同步执行，尽量避免分支分歧
2. **内存层次**：合理使用不同层级的内存
3. **SM 调度**：保持 SM 有足够的活跃线程束
4. **并行度**：足够的线程数量隐藏内存延迟

掌握这些概念将帮助你写出更高效的 GPU 程序。
